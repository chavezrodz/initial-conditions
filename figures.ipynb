{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from Datamodule  import DataModule\n",
    "from pytorch_lightning import Trainer\n",
    "from load_model import load_model\n",
    "\n",
    "predict=True\n",
    "visualize=True\n",
    "export=False\n",
    "num_workers=8\n",
    "results_dir='Results'\n",
    "datapath='data'\n",
    "\n",
    "# data params\n",
    "train_res='128x128'\n",
    "train_energy='all'\n",
    "test_res='128x128'\n",
    "test_energy='193'\n",
    "max_samples=-1\n",
    "batch_size=4\n",
    "cached=False\n",
    "\n",
    "# training params\n",
    "criterion='sq_err'\n",
    "lr=1e-3\n",
    "amsgrad=True\n",
    "\n",
    "# Model Params\n",
    "model='MLP'\n",
    "n_layers=4\n",
    "h_dim=32\n",
    "k_size=3\n",
    "pc_err='1.80e-01'\n",
    "\n",
    "saved=True\n",
    "\n",
    "def visualize_target_output(pred, y):\n",
    "    pred, y = pred.mean(dim=0), y.mean(dim=0)\n",
    "\n",
    "    minmin = torch.min(torch.tensor(\n",
    "        [pred.min().item(), y.min().item()]\n",
    "        ))\n",
    "\n",
    "    maxmax = torch.max(torch.tensor(\n",
    "        [pred.max().item(), y.max().item()]\n",
    "        ))\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, sharey=True, sharex=True)\n",
    "    im = axs[0].imshow(pred, vmin=minmin, vmax=maxmax, cmap='bone')\n",
    "    im = axs[1].imshow(y, vmin=minmin, vmax=maxmax, cmap='bone')\n",
    "\n",
    "    axs[0].set_title('Prediction')\n",
    "    axs[1].set_title('Target')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    cbar_ax = fig.add_axes([0.88, 0.15, 0.04, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t missing 5020 366.dat\n",
      "\t missing 5020 126.dat\n",
      "\t missing 5020 393.dat\n",
      "\t missing 5020 278.dat\n",
      "\t missing 5020 61.dat\n",
      "\t missing 5020 220.dat\n",
      "\t missing 5020 497.dat\n",
      "\t missing 5020 422.dat\n",
      "\t missing 5020 266.dat\n",
      "\t missing 5020 42.dat\n",
      "\t missing 5020 76.dat\n",
      "\t missing 5020 285.dat\n",
      "\t missing 5020 37.dat\n",
      "\t missing 5020 304.dat\n",
      "\t missing 5020 450.dat\n",
      "\t missing 5020 353.dat\n",
      "\t missing 5020 379.dat\n",
      "\t missing 5020 44.dat\n",
      "\t missing 5020 446.dat\n",
      "\t missing 5020 321.dat\n",
      "\t missing 5020 355.dat\n",
      "\t missing 5020 401.dat\n",
      "\t missing 5020 28.dat\n",
      "\t missing 5020 166.dat\n",
      "\t missing 5020 93.dat\n",
      "\t missing 5020 177.dat\n",
      "\t missing 5020 435.dat\n",
      "\t missing 5020 214.dat\n",
      "\t missing 5020 12.dat\n",
      "\t missing 5020 77.dat\n",
      "\t missing 5020 39.dat\n",
      "\t missing 5020 9.dat\n",
      "\t missing 5020 170.dat\n",
      "\t missing 5020 410.dat\n",
      "\t missing 5020 271.dat\n",
      "\t missing 5020 344.dat\n",
      "\t missing 5020 53.dat\n",
      "\t missing 5020 338.dat\n",
      "\t missing 5020 69.dat\n",
      "\t missing 5020 449.dat\n",
      "\t missing 5020 145.dat\n",
      "\t missing 5020 361.dat\n",
      "\t missing 5020 305.dat\n",
      "\t missing 5020 113.dat\n",
      "\t missing 5020 371.dat\n",
      "\t missing 5020 202.dat\n",
      "\t missing 5020 457.dat\n",
      "\t missing 5020 409.dat\n",
      "\t missing 5020 339.dat\n",
      "\t missing 5020 336.dat\n",
      "\t missing 5020 489.dat\n",
      "\t missing 5020 71.dat\n",
      "\t missing 5020 45.dat\n",
      "\t missing 5020 303.dat\n",
      "\t missing 5020 203.dat\n",
      "\t missing 5020 282.dat\n",
      "\t missing 5020 326.dat\n",
      "\t missing 5020 268.dat\n",
      "\t missing 5020 60.dat\n",
      "\t missing 5020 204.dat\n",
      "\t missing 5020 345.dat\n",
      "\t missing 5020 66.dat\n",
      "\t missing 5020 267.dat\n",
      "\t missing 5020 115.dat\n",
      "\t missing 5020 229.dat\n",
      "\t missing 5020 121.dat\n",
      "\t missing 5020 376.dat\n",
      "\t missing 5020 15.dat\n",
      "\t missing 5020 253.dat\n",
      "\t missing 5020 327.dat\n",
      "\t missing 5020 385.dat\n",
      "\t missing 5020 279.dat\n",
      "\t missing 5020 329.dat\n",
      "\t missing 5020 227.dat\n",
      "\t missing 5020 171.dat\n",
      "\t missing 5020 330.dat\n",
      "\t missing 5020 78.dat\n",
      "\t missing 5020 67.dat\n",
      "\t missing 5020 419.dat\n",
      "\t missing 5020 486.dat\n",
      "\t missing 5020 465.dat\n",
      "\t missing 5020 377.dat\n",
      "\t missing 5020 312.dat\n",
      "\t missing 5020 105.dat\n",
      "\t missing 5020 408.dat\n",
      "\t missing 5020 441.dat\n",
      "\t missing 5020 496.dat\n",
      "\t missing 5020 352.dat\n",
      "\t missing 5020 142.dat\n",
      "\t missing 5020 95.dat\n",
      "\t missing 5020 30.dat\n",
      "\t missing 5020 26.dat\n",
      "\t missing 5020 474.dat\n",
      "\t missing 5020 155.dat\n",
      "\t missing 5020 488.dat\n",
      "\t missing 5020 94.dat\n",
      "\t missing 5020 161.dat\n",
      "\t missing 5020 283.dat\n",
      "\t missing 5020 6.dat\n",
      "\t missing 5020 144.dat\n",
      "\t missing 5020 192.dat\n",
      "\t missing 5020 463.dat\n",
      "\t missing 5020 245.dat\n",
      "\t missing 5020 54.dat\n",
      "\t missing 5020 127.dat\n",
      "\t missing 5020 1.dat\n",
      "\t missing 5020 254.dat\n",
      "\t missing 5020 343.dat\n",
      "\t missing 5020 102.dat\n",
      "\t missing 5020 226.dat\n",
      "\t missing 5020 205.dat\n",
      "\t missing 5020 313.dat\n",
      "\t missing 5020 169.dat\n",
      "\t missing 5020 221.dat\n",
      "\t missing 5020 114.dat\n",
      "\t missing 5020 462.dat\n",
      "\t missing 5020 104.dat\n",
      "\t missing 5020 331.dat\n",
      "\t missing 5020 382.dat\n",
      "\t missing 5020 215.dat\n",
      "\t missing 5020 230.dat\n",
      "\t missing 5020 434.dat\n",
      "\t missing 5020 417.dat\n",
      "\t missing 5020 213.dat\n",
      "\t missing 5020 447.dat\n",
      "\t missing 5020 178.dat\n",
      "\t missing 5020 472.dat\n",
      "\t missing 5020 83.dat\n",
      "\t missing 5020 261.dat\n",
      "\t missing 5020 490.dat\n",
      "\t missing 5020 179.dat\n",
      "\t missing 5020 406.dat\n",
      "\t missing 5020 193.dat\n",
      "\t missing 5020 499.dat\n",
      "\t missing 5020 276.dat\n",
      "\t missing 5020 52.dat\n",
      "\t missing 5020 425.dat\n",
      "\t missing 5020 239.dat\n",
      "\t missing 5020 195.dat\n",
      "\t missing 5020 136.dat\n",
      "\t missing 5020 498.dat\n",
      "\t missing 5020 160.dat\n",
      "\t missing 5020 43.dat\n",
      "\t missing 5020 294.dat\n",
      "\t missing 5020 31.dat\n",
      "\t missing 5020 167.dat\n",
      "\t missing 5020 260.dat\n",
      "\t missing 5020 112.dat\n",
      "\t missing 5020 13.dat\n",
      "\t missing 5020 255.dat\n",
      "\t missing 5020 383.dat\n",
      "\t missing 5020 433.dat\n",
      "\t missing 5020 328.dat\n",
      "\t missing 5020 314.dat\n",
      "\t missing 5020 231.dat\n",
      "\t missing 5020 38.dat\n",
      "\t missing 5020 424.dat\n",
      "\t missing 5020 82.dat\n",
      "\t missing 5020 459.dat\n",
      "\t missing 5020 242.dat\n",
      "\t missing 5020 448.dat\n",
      "\t missing 5020 440.dat\n",
      "\t missing 5020 392.dat\n",
      "\t missing 5020 378.dat\n",
      "\t missing 5020 139.dat\n",
      "\t missing 5020 130.dat\n",
      "\t missing 5020 370.dat\n",
      "\t missing 5020 8.dat\n",
      "\t missing 5020 284.dat\n",
      "\t missing 5020 481.dat\n",
      "\t missing 5020 184.dat\n",
      "\t missing 5020 103.dat\n",
      "\t missing 5020 228.dat\n",
      "\t missing 5020 458.dat\n",
      "\t missing 5020 168.dat\n",
      "\t missing 5020 369.dat\n",
      "\t missing 5020 432.dat\n",
      "\t missing 5020 68.dat\n",
      "\t missing 5020 384.dat\n",
      "\t missing 5020 236.dat\n",
      "\t missing 5020 395.dat\n",
      "\t missing 5020 302.dat\n",
      "\t missing 5020 176.dat\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     logger\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m     accelerator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     devices\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     )\n\u001b[1;32m      7\u001b[0m dm_trained \u001b[39m=\u001b[39m DataModule(datapath\u001b[39m=\u001b[39mdatapath,\n\u001b[1;32m      8\u001b[0m                         cached\u001b[39m=\u001b[39mcached,\n\u001b[1;32m      9\u001b[0m                         max_samples\u001b[39m=\u001b[39mmax_samples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m                         energy\u001b[39m=\u001b[39mtest_energy,\n\u001b[1;32m     14\u001b[0m                         stage\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m dm_trained\u001b[39m.\u001b[39;49mprepare_data()\n\u001b[1;32m     17\u001b[0m model, model_name \u001b[39m=\u001b[39m load_model(model, h_dim, n_layers, k_size, dm, saved, results_dir, criterion, lr, amsgrad, pc_err)\n\u001b[1;32m     18\u001b[0m \u001b[39mdel\u001b[39;00m dm_trained\n",
      "File \u001b[0;32m~/Desktop/McGill/Research/initial-conditions/Datamodule.py:121\u001b[0m, in \u001b[0;36mDataModule.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(outfile):\n\u001b[1;32m    120\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m missing \u001b[39m\u001b[39m{\u001b[39;00menergy\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m                 save_checkpt(filename, outfile)\n\u001b[1;32m    123\u001b[0m \u001b[39m# If norms dont exist make them\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorms_file):\n",
      "File \u001b[0;32m~/Desktop/McGill/Research/initial-conditions/Datamodule.py:10\u001b[0m, in \u001b[0;36msave_checkpt\u001b[0;34m(filename, outfile)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_checkpt\u001b[39m(filename, outfile):\n\u001b[0;32m---> 10\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(filename)\n\u001b[1;32m     11\u001b[0m     A \u001b[39m=\u001b[39m two_to_three(arr)\n\u001b[1;32m     12\u001b[0m     A \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtranspose(A, (\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/McGill/Research/initial-conditions/.venv/lib/python3.8/site-packages/numpy/lib/npyio.py:1313\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1311\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1313\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[1;32m   1314\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m   1315\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1316\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[1;32m   1318\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/Desktop/McGill/Research/initial-conditions/.venv/lib/python3.8/site-packages/numpy/lib/npyio.py:979\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    976\u001b[0m     data \u001b[39m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m    978\u001b[0m \u001b[39mif\u001b[39;00m read_dtype_via_object_chunks \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 979\u001b[0m     arr \u001b[39m=\u001b[39m _load_from_filelike(\n\u001b[1;32m    980\u001b[0m         data, delimiter\u001b[39m=\u001b[39;49mdelimiter, comment\u001b[39m=\u001b[39;49mcomment, quote\u001b[39m=\u001b[39;49mquote,\n\u001b[1;32m    981\u001b[0m         imaginary_unit\u001b[39m=\u001b[39;49mimaginary_unit,\n\u001b[1;32m    982\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols, skiplines\u001b[39m=\u001b[39;49mskiplines, max_rows\u001b[39m=\u001b[39;49mmax_rows,\n\u001b[1;32m    983\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    984\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding, filelike\u001b[39m=\u001b[39;49mfilelike,\n\u001b[1;32m    985\u001b[0m         byte_converters\u001b[39m=\u001b[39;49mbyte_converters)\n\u001b[1;32m    987\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m     \u001b[39m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[39m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[39m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     \u001b[39m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     \u001b[39mif\u001b[39;00m filelike:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/codecs.py:331\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.getstate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m     IncrementalDecoder\u001b[39m.\u001b[39mreset(\u001b[39mself\u001b[39m)\n\u001b[1;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetstate\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    332\u001b[0m     \u001b[39m# additional state info is always 0\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer, \u001b[39m0\u001b[39m)\n\u001b[1;32m    335\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetstate\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m    336\u001b[0m     \u001b[39m# ignore additional state info\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    logger=False,\n",
    "    accelerator='auto',\n",
    "    devices='auto',\n",
    "    )\n",
    "\n",
    "dm_trained = DataModule(datapath=datapath,\n",
    "                        cached=cached,\n",
    "                        max_samples=max_samples,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=num_workers,\n",
    "                        res=test_res,\n",
    "                        energy=test_energy,\n",
    "                        stage='train')\n",
    "\n",
    "dm_trained.prepare_data()\n",
    "model, model_name = load_model(model, h_dim, n_layers, k_size, dm, saved, results_dir, criterion, lr, amsgrad, pc_err)\n",
    "del dm_trained\n",
    "\n",
    "dm_test = DataModule(args, stage='test')\n",
    "trainer.test(model=model, datamodule=dm_test)\n",
    "\n",
    "# for batch in predictions:\n",
    "#     pred, target, fns = batch\n",
    "#     for idx, file_nb in enumerate(fns):\n",
    "#         visualize_target_output(pred[idx].detach(), target[idx].detach())\n",
    "\n",
    "# pass\n",
    "\n",
    "outfolder = os.path.join('Results', 'Predictions', model_name, args.test_res, args.test_energy)\n",
    "os.makedirs(outfolder, exist_ok=True)\n",
    "model.outfolder = outfolder\n",
    "\n",
    "sample_file = os.path.join('data',args.test_res, args.test_energy,'0.dat')\n",
    "f = open(sample_file, 'r')\n",
    "model.header = f.readline()\n",
    "f.close()\n",
    "\n",
    "data_sample = np.loadtxt(sample_file)\n",
    "model.x_values = np.sort(np.unique(data_sample[:, 0]))\n",
    "\n",
    "trainer.predict(model, datamodule=dm_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
